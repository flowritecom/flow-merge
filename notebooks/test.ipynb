{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ValidatedInputData(method=<MergeMethodIdentifier.DARE_TIES_MERGING: 'dare-ties-merging'>, method_global_parameters=MethodGlobalParameters(scaling_coefficient=0.7, normalize=False, p=0.7, t=None, top_k=None), base_model='Qwen/Qwen1.5-0.5B', models=[RawModelDict(path_or_id='Qwen/Qwen1.5-0.5B', weight=0.5), RawModelDict(path_or_id='Qwen/Qwen1.5-0.5B-chat', weight=0.3), RawModelDict(path_or_id='minghaowu/Qwen1.5-0.5B-OpenHermes-2.5', weight=0.3)], tokenizer_settings=TokenizerSettings(mode='base', interpolation_method='linear'), directory_settings=DirectorySettings(cache_dir=None, local_dir=PosixPath('/Users/minaamshahid/projects/flowrite/flow-merge/notebooks/models'), output_dir=PosixPath('/Users/minaamshahid/projects/flowrite/flow-merge/notebooks/ties_merging_model')), hf_hub_settings=HfHubSettings(token=None, trust_remote_code=False), device=None)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "flow_merge.lib.model_metadata - INFO - Model metadata created!\n",
      "flow_merge.lib.model_metadata - INFO - Model metadata created!\n",
      "flow_merge.lib.model_metadata - INFO - Model metadata created!\n",
      "flow_merge.lib.model_metadata - INFO - Model metadata created!\n",
      "flow_merge.lib.model_metadata - INFO - Model metadata created!\n",
      "flow_merge.lib.model_metadata - INFO - Model metadata created!\n",
      "flow_merge.lib.model_metadata - INFO - Model metadata created!\n",
      "flow_merge.lib.model_metadata - INFO - Model metadata created!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelInfo(id='Qwen/Qwen1.5-0.5B',\n",
      "          author='Qwen',\n",
      "          sha='8f445e3628f3500ee69f24e1303c9f10f5342a39',\n",
      "          created_at=datetime.datetime(2024, 1, 22, 16, 30, 10, tzinfo=datetime.timezone.utc),\n",
      "          last_modified=datetime.datetime(2024, 4, 5, 10, 38, 41, tzinfo=datetime.timezone.utc),\n",
      "          private=False,\n",
      "          gated=False,\n",
      "          disabled=False,\n",
      "          downloads=55923,\n",
      "          likes=116,\n",
      "          library_name='transformers',\n",
      "          tags=['transformers',\n",
      "                'safetensors',\n",
      "                'qwen2',\n",
      "                'text-generation',\n",
      "                'pretrained',\n",
      "                'conversational',\n",
      "                'en',\n",
      "                'license:other',\n",
      "                'autotrain_compatible',\n",
      "                'endpoints_compatible',\n",
      "                'text-generation-inference',\n",
      "                'region:us'],\n",
      "          pipeline_tag='text-generation',\n",
      "          mask_token=None,\n",
      "          card_data={'language': ['en'], 'license': 'other', 'library_name': None, 'tags': ['pretrained'], 'base_model': None, 'datasets': None, 'metrics': None, 'eval_results': None, 'model_name': None, 'license_name': 'tongyi-qianwen-research', 'license_link': 'https://huggingface.co/Qwen/Qwen1.5-0.5B/blob/main/LICENSE', 'pipeline_tag': 'text-generation'},\n",
      "          widget_data=[{'text': 'Hey my name is Julien! How are you?'},\n",
      "                       {'text': 'Hey my name is Thomas! How are you?'},\n",
      "                       {'text': 'Hey my name is Mariama! How are you?'},\n",
      "                       {'text': 'Hey my name is Clara! How are you?'},\n",
      "                       {'text': 'Hey my name is Julien! How are you?'},\n",
      "                       {'text': 'Hi.'}],\n",
      "          model_index=None,\n",
      "          config={'architectures': ['Qwen2ForCausalLM'],\n",
      "                  'model_type': 'qwen2',\n",
      "                  'tokenizer_config': {'bos_token': None,\n",
      "                                       'chat_template': '{% for message in '\n",
      "                                                        'messages %}{% if '\n",
      "                                                        'loop.first and '\n",
      "                                                        \"messages[0]['role'] \"\n",
      "                                                        \"!= 'system' %}{{ \"\n",
      "                                                        \"'<|im_start|>system\\n\"\n",
      "                                                        'You are a helpful '\n",
      "                                                        'assistant<|im_end|>\\n'\n",
      "                                                        \"' }}{% endif \"\n",
      "                                                        \"%}{{'<|im_start|>' + \"\n",
      "                                                        \"message['role'] + '\\n\"\n",
      "                                                        \"' + \"\n",
      "                                                        \"message['content'] + \"\n",
      "                                                        \"'<|im_end|>' + '\\n\"\n",
      "                                                        \"'}}{% endfor %}{% if \"\n",
      "                                                        'add_generation_prompt '\n",
      "                                                        '%}{{ '\n",
      "                                                        \"'<|im_start|>assistant\\n\"\n",
      "                                                        \"' }}{% endif %}\",\n",
      "                                       'eos_token': '<|endoftext|>',\n",
      "                                       'pad_token': '<|endoftext|>',\n",
      "                                       'unk_token': None}},\n",
      "          transformers_info=TransformersInfo(auto_model='AutoModelForCausalLM',\n",
      "                                             custom_class=None,\n",
      "                                             pipeline_tag='text-generation',\n",
      "                                             processor='AutoTokenizer'),\n",
      "          siblings=[RepoSibling(rfilename='.gitattributes',\n",
      "                                size=1519,\n",
      "                                blob_id='a6344aac8c09253b3b630fb776ae94478aa0275b',\n",
      "                                lfs=None),\n",
      "                    RepoSibling(rfilename='LICENSE',\n",
      "                                size=7281,\n",
      "                                blob_id='c5faab3b0ab37a1f8fe7067d963bf30e8735d7e1',\n",
      "                                lfs=None),\n",
      "                    RepoSibling(rfilename='README.md',\n",
      "                                size=2773,\n",
      "                                blob_id='3459525f3220f8a7fa2222fbee09b34b517c17d1',\n",
      "                                lfs=None),\n",
      "                    RepoSibling(rfilename='config.json',\n",
      "                                size=661,\n",
      "                                blob_id='7933f98f3efce9098c93c8905d44e0f090fd860b',\n",
      "                                lfs=None),\n",
      "                    RepoSibling(rfilename='generation_config.json',\n",
      "                                size=138,\n",
      "                                blob_id='cbbb3133034e192527e5321b4c679154e4819ab8',\n",
      "                                lfs=None),\n",
      "                    RepoSibling(rfilename='merges.txt',\n",
      "                                size=1671839,\n",
      "                                blob_id='20024bfe7c83998e9aeaf98a0cd6a2ce6306c2f0',\n",
      "                                lfs=None),\n",
      "                    RepoSibling(rfilename='model.safetensors',\n",
      "                                size=1239173352,\n",
      "                                blob_id='b7d0bc99ada929da4ff0e73bd510c8697db2e702',\n",
      "                                lfs=BlobLfsInfo(size=1239173352,\n",
      "                                                sha256='a88bcf41b3fa9a20031b6b598abc11f694e35e0b5684d6e14dbe7e894ebbb080',\n",
      "                                                pointer_size=135)),\n",
      "                    RepoSibling(rfilename='tokenizer.json',\n",
      "                                size=7028015,\n",
      "                                blob_id='33ea6c72ebb92a237fa2bdf26c5ff16592efcdae',\n",
      "                                lfs=None),\n",
      "                    RepoSibling(rfilename='tokenizer_config.json',\n",
      "                                size=1289,\n",
      "                                blob_id='f4b55f917af273d0dc98b67ec249f6445dd385f5',\n",
      "                                lfs=None),\n",
      "                    RepoSibling(rfilename='vocab.json',\n",
      "                                size=2776833,\n",
      "                                blob_id='4783fe10ac3adce15ac8f358ef5462739852c569',\n",
      "                                lfs=None)],\n",
      "          spaces=['eduagarcia/open_pt_llm_leaderboard',\n",
      "                  'rockyripple04/Qwen-Qwen1.5-0.5B',\n",
      "                  'lingchmao/medassist-liver-cancer',\n",
      "                  'nubifere/vis-llm-ft',\n",
      "                  'duclinhof/Qwen-Qwen1.5-0.5B',\n",
      "                  'isimorfizam/QuerySummarizer',\n",
      "                  'lpr666/Qwen-Qwen1.5-0.5B',\n",
      "                  'Ibrahimarain/llama-2-13B',\n",
      "                  'aelitta/BioMistral_gradio'],\n",
      "          safetensors=SafeTensorsInfo(parameters={'BF16': 619570176},\n",
      "                                      total=619570176))\n",
      "\n",
      "\n",
      "a6344aac8c09253b3b630fb776ae94478aa0275b\n",
      ".gitattributes\n",
      "1519\n",
      "RepoSibling(rfilename='.gitattributes', size=1519, blob_id='a6344aac8c09253b3b630fb776ae94478aa0275b', lfs=None)\n",
      "\n",
      "\n",
      "c5faab3b0ab37a1f8fe7067d963bf30e8735d7e1\n",
      "LICENSE\n",
      "7281\n",
      "RepoSibling(rfilename='LICENSE', size=7281, blob_id='c5faab3b0ab37a1f8fe7067d963bf30e8735d7e1', lfs=None)\n",
      "\n",
      "\n",
      "3459525f3220f8a7fa2222fbee09b34b517c17d1\n",
      "README.md\n",
      "2773\n",
      "RepoSibling(rfilename='README.md', size=2773, blob_id='3459525f3220f8a7fa2222fbee09b34b517c17d1', lfs=None)\n",
      "\n",
      "\n",
      "7933f98f3efce9098c93c8905d44e0f090fd860b\n",
      "config.json\n",
      "661\n",
      "RepoSibling(rfilename='config.json', size=661, blob_id='7933f98f3efce9098c93c8905d44e0f090fd860b', lfs=None)\n",
      "\n",
      "\n",
      "cbbb3133034e192527e5321b4c679154e4819ab8\n",
      "generation_config.json\n",
      "138\n",
      "RepoSibling(rfilename='generation_config.json', size=138, blob_id='cbbb3133034e192527e5321b4c679154e4819ab8', lfs=None)\n",
      "\n",
      "\n",
      "20024bfe7c83998e9aeaf98a0cd6a2ce6306c2f0\n",
      "merges.txt\n",
      "1671839\n",
      "RepoSibling(rfilename='merges.txt', size=1671839, blob_id='20024bfe7c83998e9aeaf98a0cd6a2ce6306c2f0', lfs=None)\n",
      "\n",
      "\n",
      "b7d0bc99ada929da4ff0e73bd510c8697db2e702\n",
      "model.safetensors\n",
      "1239173352\n",
      "RepoSibling(rfilename='model.safetensors', size=1239173352, blob_id='b7d0bc99ada929da4ff0e73bd510c8697db2e702', lfs=BlobLfsInfo(size=1239173352, sha256='a88bcf41b3fa9a20031b6b598abc11f694e35e0b5684d6e14dbe7e894ebbb080', pointer_size=135))\n",
      "a88bcf41b3fa9a20031b6b598abc11f694e35e0b5684d6e14dbe7e894ebbb080\n",
      "135\n",
      "\n",
      "\n",
      "33ea6c72ebb92a237fa2bdf26c5ff16592efcdae\n",
      "tokenizer.json\n",
      "7028015\n",
      "RepoSibling(rfilename='tokenizer.json', size=7028015, blob_id='33ea6c72ebb92a237fa2bdf26c5ff16592efcdae', lfs=None)\n",
      "\n",
      "\n",
      "f4b55f917af273d0dc98b67ec249f6445dd385f5\n",
      "tokenizer_config.json\n",
      "1289\n",
      "RepoSibling(rfilename='tokenizer_config.json', size=1289, blob_id='f4b55f917af273d0dc98b67ec249f6445dd385f5', lfs=None)\n",
      "\n",
      "\n",
      "4783fe10ac3adce15ac8f358ef5462739852c569\n",
      "vocab.json\n",
      "2776833\n",
      "RepoSibling(rfilename='vocab.json', size=2776833, blob_id='4783fe10ac3adce15ac8f358ef5462739852c569', lfs=None)\n",
      "{'BF16': 619570176}\n",
      "619570176\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %load_ext autoreload --quiet\n",
    "except ImportError:\n",
    "    %reload_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "from dataclasses import asdict\n",
    "import yaml\n",
    "from flow_merge.lib.merge_config import ValidatedInputData, MergeConfig\n",
    "# from flow_merge.lib.tensor_loader import ModelSourceMetadata\n",
    "from flow_merge.lib.model_metadata import load_model_info\n",
    "from pprint import pprint\n",
    "from huggingface_hub.hf_api import ModelInfo, RepoSibling, SafeTensorsInfo, BlobLfsInfo\n",
    "\n",
    "\n",
    "file_path = \"../examples/dare_ties_config.yaml\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    unvalidated_data = yaml.safe_load(file)\n",
    "\n",
    "vd = ValidatedInputData(**unvalidated_data)\n",
    "# mc = MergeConfig.from_yaml(\"../examples/dare_ties_config.yaml\")\n",
    "#md = ModelSourceMetadata.from_model_path(\"minghaowu/Qwen1.5-0.5B-OpenHermes-2.5\", mc)\n",
    "\n",
    "# print out nice outputs using export\n",
    "print(\"\\n\")\n",
    "pprint(vd)\n",
    "print(\"\\n\")\n",
    "# pprint(mc)\n",
    "print(\"\\n\")\n",
    "# pprint(md)\n",
    "\n",
    "# rd = ModelSourceMetadata.fetch_from_hf(\"minghaowu/Qwen1.5-0.5B-OpenHermes-2.5\")\n",
    "rd = load_model_info(\"Qwen/Qwen1.5-0.5B\")\n",
    "\n",
    "pprint(rd)\n",
    "\n",
    "\n",
    "for i in rd.siblings:\n",
    "    print(f\"\\n\\n{i.blob_id}\\n{i.rfilename}\\n{i.size}\")\n",
    "    print(i)\n",
    "    if i.lfs:\n",
    "        print(i.lfs.sha256)\n",
    "        print(i.lfs.pointer_size)\n",
    "\n",
    "# if rd.transformers_info:\n",
    "#     print(rd.transformers_info)\n",
    "    \n",
    "if rd.safetensors:\n",
    "    print(rd.safetensors.parameters)\n",
    "    print(rd.safetensors.total)\n",
    "# print(rd.sha)\n",
    "# print(rd.created_at)\n",
    "# print(rd.last_modified)\n",
    "# print(rd.private)\n",
    "# print(rd.gated)\n",
    "# print(rd.disabled)\n",
    "# print(rd.mask_token)\n",
    "# print(rd.model_index)\n",
    "\n",
    "### IMMEDIATE TODOS\n",
    "# 1. create the modelsourcemetadata\n",
    "# -> take in the file metadata\n",
    "# -> do the file checks\n",
    "\n",
    "# 2. include it in MergeConfig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### LATER TODOS\n",
    "## 1. upload function to import HF_TOKEN as optional argument, and choose on priority - to Arek\n",
    "## 2. use token in the merge_config\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FileMetadata(filename='.gitattributes', sha='11ad7efa24975ee4b0c3c3a38ed18737f0658a5f75a0a96787b576a78a023361', blob_id='a6344aac8c09253b3b630fb776ae94478aa0275b', size=1519, lfs=None),\n",
       " FileMetadata(filename='LICENSE', sha='41c2cf8c272f6fb0080a97cd9d9bd7d4604072b80a0b10e7d65ca26ef5000c0c', blob_id='c5faab3b0ab37a1f8fe7067d963bf30e8735d7e1', size=7281, lfs=None),\n",
       " FileMetadata(filename='README.md', sha='a1f74fb8b65e90381e38aecb1f97f035d58b886a8ba327373ee203cd15074703', blob_id='3459525f3220f8a7fa2222fbee09b34b517c17d1', size=2773, lfs=None),\n",
       " FileMetadata(filename='config.json', sha='fa5ce2577a12b2c41aab208242c3de5bdcc4309d147842ad88040b6d4349fc36', blob_id='7933f98f3efce9098c93c8905d44e0f090fd860b', size=661, lfs=None),\n",
       " FileMetadata(filename='generation_config.json', sha='8c970692323e3ea0e9b8b0a4dca79388d31226e41f83c9fd6014804280ebf6e8', blob_id='cbbb3133034e192527e5321b4c679154e4819ab8', size=138, lfs=None),\n",
       " FileMetadata(filename='merges.txt', sha='599bab54075088774b1733fde865d5bd747cbcc7a547c5bc12610e874e26f5e3', blob_id='20024bfe7c83998e9aeaf98a0cd6a2ce6306c2f0', size=1671839, lfs=None),\n",
       " FileMetadata(filename='model.safetensors', sha='a88bcf41b3fa9a20031b6b598abc11f694e35e0b5684d6e14dbe7e894ebbb080', blob_id='b7d0bc99ada929da4ff0e73bd510c8697db2e702', size=1239173352, lfs=BlobLfsInfo(size=1239173352, sha256='a88bcf41b3fa9a20031b6b598abc11f694e35e0b5684d6e14dbe7e894ebbb080', pointer_size=135)),\n",
       " FileMetadata(filename='tokenizer.json', sha='f7c9b2dba4a296b1aa76c16a34b8225c0c118978400d4bb66bff0902d702f5b8', blob_id='33ea6c72ebb92a237fa2bdf26c5ff16592efcdae', size=7028015, lfs=None),\n",
       " FileMetadata(filename='tokenizer_config.json', sha='80d64fccf954f022eb43b7425eb45a133cbb92c76a5f24d4cea6dbe3d45548d9', blob_id='f4b55f917af273d0dc98b67ec249f6445dd385f5', size=1289, lfs=None),\n",
       " FileMetadata(filename='vocab.json', sha='ca10d7e9fb3ed18575dd1e277a2579c16d108e32f27439684afa0e10b1440910', blob_id='4783fe10ac3adce15ac8f358ef5462739852c569', size=2776833, lfs=None)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flow_merge.lib.model_metadata import load_model_info\n",
    "\n",
    "p = \"Qwen/Qwen1.5-0.5B\"\n",
    "\n",
    "model_metadata = load_model_info(path_or_id=p, model_path=\"./models/\")\n",
    "model_metadata.file_metadata_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vocab_size': 151936, 'max_position_embeddings': 32768, 'hidden_size': 1024, 'intermediate_size': 2816, 'num_hidden_layers': 24, 'num_attention_heads': 16, 'use_sliding_window': False, 'sliding_window': 32768, 'max_window_layers': 21, 'num_key_value_heads': 16, 'hidden_act': 'silu', 'initializer_range': 0.02, 'rms_norm_eps': 1e-06, 'use_cache': True, 'rope_theta': 1000000.0, 'attention_dropout': 0.0, 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'bfloat16', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['Qwen2ForCausalLM'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 151643, 'pad_token_id': None, 'eos_token_id': 151643, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': '/Users/minaamshahid/projects/flowrite/flow-merge/models/Qwen/Qwen1.5-0.5B', 'transformers_version': '4.38.1', 'model_type': 'qwen2'}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'sha256'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(path_to_model)\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(config)\n\u001b[0;32m---> 12\u001b[0m config\u001b[38;5;241m.\u001b[39msha256\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'sha256'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from transformers import AutoConfig\n",
    "\n",
    "p = \"Qwen/Qwen1.5-0.5B\"\n",
    "base = \"../models/\"\n",
    "\n",
    "path_to_model = Path(base + p).resolve()\n",
    "\n",
    "if path_to_model.exists():\n",
    "    config = AutoConfig.from_pretrained(path_to_model).to_dict()\n",
    "    print(config)\n",
    "    config.sha256"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow-merge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
